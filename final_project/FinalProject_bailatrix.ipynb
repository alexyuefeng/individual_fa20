{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp has become infamous among business owners for the open door it offers frustrated consumers who may not have had a representative experience at a facility. But are reviews really so reactive, or is there consistency between the content of a review and its rating? Are some ratings more reliable than others? It can be difficult to process blanket criticism from outsiders, but if Yelp review content had measured correlation with review rating (and therefore, ranking of the business on its site), it might provide guidance to anyone trying to use the reviews to improve the business (or park!). Unfortunately, the sentiment analysis conducted in this investigation did not demonstrate a strong statistical significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name & GitHub\n",
    "\n",
    "- Name: Bailey Passmore\n",
    "- GitHub Username: bailatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the content of a Yelp review an accurate predictor of the sentiment of its rating? Further, is the prediction quality equal for all 5 rating options, or do some ratings see more reliable predictions than others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In past years, I worked for a contractor who was constantly battling his Yelp rating and simply could not figure out how to have a \"fair\" rating on the site. He tried getting new customers to write reviews, that worked sometimes but a lot of people didn't think it significant. He offered to help customers who didn't have a Yelp account to sign-up or even provide a monetary reward, but he was instructed his business could not involve itself in the review process like that.\n",
    "\n",
    "In fact, Yelp has a very particular set of rules[1] it expects businesses and organizations on its platform to follow to maintain good standing with consumers. Countless articles and blogs online offer suggests to improve Yelp ratings [2] and recover from bad reviews, but these results are slow to become fruitful and it begs the question, how strong is the link between review sentiment and review rating? If the caliber expected of a business owner could be expected from the consumer writing the review, the review data should contain reliable features to use in predictions.\n",
    "\n",
    "References (include links):\n",
    "- [1] https://www.reviewtrackers.com/blog/yelp-factsheet/\n",
    "- [2] https://www.wordstream.com/blog/ws/2013/07/22/yelp-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review content should be predictive of ratings, at least in the case of lower ratings seeing more accuracy. This could be expected because a more negative experience may standout more than a neutral or generally positive experience might, and this could inform greater detail of review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset Name:    `yelp_SD_reviews.csv`\n",
    "- Number of observations:    2333\n",
    "- Link to the dataset:    https://github.com/COGS108/individual_fa20/blob/master/data/yelp_SD_reviews.csv\n",
    "- Dataset documentation:    https://github.com/COGS108/individual_fa20/blob/master/data/README.md#san-diego-parks-yelp-data\n",
    "\n",
    "This dataset makes up just over 2,000 Yelp reviews for parks in San Diego, CA, USA. The columns available are:\n",
    "* `id`:    Subject of the review (the park)\n",
    "* `rating`:    Rating of review (out of 5 stars)\n",
    "* `text`:    Text of review (raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/baileyp/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/baileyp/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_src = '../data/yelp_SD_reviews.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset shows a heavily redacted and anonymized version of the original sample set, so there is nothing more to reduce from the features of the data. In terms of cleanliness, it's still useful to check for null or empty values, but the dataset is in great shape for the tests applied in this investigation.\n",
    "\n",
    "The vectorizers needed for the next step of text analysis are also prepared in this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "rating    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df = pd.read_csv( rev_src )\n",
    "rev_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2333, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balboa Park</td>\n",
       "      <td>5</td>\n",
       "      <td>Balboa Park is a must see when coming to San D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Balboa Park</td>\n",
       "      <td>5</td>\n",
       "      <td>Beautiful grounds even to take a stroll during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Balboa Park</td>\n",
       "      <td>5</td>\n",
       "      <td>Beautiful sightseeing in San Diego. Lots of wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Civita Park</td>\n",
       "      <td>5</td>\n",
       "      <td>Was invited to child's B-Day party pre Covid-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Civita Park</td>\n",
       "      <td>5</td>\n",
       "      <td>Pretty nice park, beautiful design.  Anyone is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  rating                                               text\n",
       "0  Balboa Park       5  Balboa Park is a must see when coming to San D...\n",
       "1  Balboa Park       5  Beautiful grounds even to take a stroll during...\n",
       "2  Balboa Park       5  Beautiful sightseeing in San Diego. Lots of wa...\n",
       "3  Civita Park       5  Was invited to child's B-Day party pre Covid-1...\n",
       "4  Civita Park       5  Pretty nice park, beautiful design.  Anyone is..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup test and training sets according to 80/20 parameter\n",
    "num_training = int( 0.8 * len(rev_df) ) \n",
    "num_testing = int( 0.2 * len(rev_df) )\n",
    "\n",
    "# setup training function\n",
    "def train_SVM(X, y, kernel='linear'):\n",
    "    clf = SVC( kernel=kernel )\n",
    "    clf = clf.fit( X, y )\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer for BoW\n",
    "vectorizer = CountVectorizer( analyzer = 'word',\n",
    "                              max_features = 2000,\n",
    "                              tokenizer = word_tokenize,\n",
    "                              stop_words = stopwords.words('english') )\n",
    "\n",
    "# vectorizer for tf-idf\n",
    "tfidf = TfidfVectorizer( sublinear_tf = True,\n",
    "                        analyzer = 'word',\n",
    "                        max_features = 2000, \n",
    "                        tokenizer = word_tokenize )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format data\n",
    "rating_count = rev_df.groupby(['rating'])['id'].count()\n",
    "plt.bar( [1, 2, 3, 4, 5], rating_count, color='lightblue', edgecolor='silver')\n",
    "\n",
    "# setup labels\n",
    "plt.xlabel('Rating', labelpad=5, fontweight='bold', fontsize='large')\n",
    "plt.ylabel('Count', labelpad=5, fontweight='bold', fontsize='large')\n",
    "plt.title('How many of each rating are in the dataset?', pad=10,\n",
    "          fontdict={'fontweight': 'bold', 'fontsize': 'x-large'})\n",
    "\n",
    "# visualization of data\n",
    "plt.gcf().set_size_inches(14, 6)\n",
    "plt.show()\n",
    "\n",
    "# Save figure as .png\n",
    "plt.savefig( \"./rating_freq.png\", bbox='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that 5-star ratings make up a majority of the data, the predictions from these reviews would hold the most practical significance, if any. We may be able to get reasonable inferences from 1-, 3-, and 4-star reviews from the sample size, but it would be much less likely to have any practical meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, separately apply each of the vectorizers and print out the results from the Bag of Words (BoW) and Term Frequency - Inverse Document Frequency (Tf-Idf) classification on the train and test sets.\n",
    "\n",
    "BoW classification standardizes sentiment between the words of a sentence and their frequency within the sentence, whereas Tf-Idf considers the frequency of those same words against the whole body of reviews, potentially informing us as to whether reviews with more distinctive patterns predict rating differently than the standard BoW classifier does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words (BoW) prediction:\n",
      "1) Train, 2) Test\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00       158\n",
      "           2       1.00      1.00      1.00        49\n",
      "           3       1.00      1.00      1.00       144\n",
      "           4       1.00      0.97      0.99       424\n",
      "           5       0.99      1.00      1.00      1091\n",
      "\n",
      "    accuracy                           0.99      1866\n",
      "   macro avg       1.00      0.99      1.00      1866\n",
      "weighted avg       0.99      0.99      0.99      1866\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.28      0.29        43\n",
      "           2       0.08      0.05      0.06        22\n",
      "           3       0.14      0.12      0.13        42\n",
      "           4       0.20      0.18      0.19        87\n",
      "           5       0.67      0.73      0.70       273\n",
      "\n",
      "    accuracy                           0.50       467\n",
      "   macro avg       0.28      0.27      0.27       467\n",
      "weighted avg       0.47      0.50      0.49       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare respective X and Y data\n",
    "rev_X = vectorizer.fit_transform( rev_df[\"text\"] ).toarray()\n",
    "rev_y = rev_df[\"rating\"].values\n",
    "\n",
    "# collect subsets of X and Y data according to train/test parameters\n",
    "rev_train_X = rev_X[ : num_training ] \n",
    "rev_train_y = rev_y[  : num_training ]\n",
    "rev_test_X = rev_X[ num_training : ]\n",
    "rev_test_y = rev_y[ num_training : ]\n",
    "\n",
    "# setup classifier and predictions\n",
    "rev_clf = train_SVM( rev_train_X, rev_train_y )\n",
    "rev_predicted_train_y = rev_clf.predict( rev_train_X )\n",
    "rev_predicted_test_y = rev_clf.predict( rev_test_X )\n",
    "\n",
    "# display classifier reports - BoW\n",
    "print(\"Bag of Words (BoW) prediction:\\n1) Train, 2) Test\\n\")\n",
    "print(classification_report(rev_train_y, rev_predicted_train_y))\n",
    "print(classification_report(rev_test_y, rev_predicted_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the BoW classifier had a training accuracy of 99%, the test set was not accurate at all, dropping down to 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Frequency - Inverse Document Frequency (Tf-Idf) prediction:\n",
      "1) Train, 2) Test\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.61      0.75       158\n",
      "           2       0.00      0.00      0.00        49\n",
      "           3       1.00      0.19      0.32       144\n",
      "           4       0.81      0.58      0.68       424\n",
      "           5       0.75      0.98      0.85      1091\n",
      "\n",
      "    accuracy                           0.77      1866\n",
      "   macro avg       0.71      0.47      0.52      1866\n",
      "weighted avg       0.78      0.77      0.74      1866\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.09      0.16        43\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.00      0.00      0.00        42\n",
      "           4       0.30      0.10      0.15        87\n",
      "           5       0.61      0.95      0.74       273\n",
      "\n",
      "    accuracy                           0.58       467\n",
      "   macro avg       0.28      0.23      0.21       467\n",
      "weighted avg       0.46      0.58      0.48       467\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare X data as tfidf vector\n",
    "rev_tfidf_X = tfidf.fit_transform( rev_df['text'].values ).toarray()\n",
    "\n",
    "# collect subsets of X and Y data according to train/test parameters\n",
    "rev_train_tfidf_X = rev_tfidf_X[ : num_training ]\n",
    "rev_train_tfidf_y = rev_y[ : num_training ]\n",
    "rev_test_tfidf_X = rev_tfidf_X[ num_training : ]\n",
    "rev_test_tfidf_y = rev_y[ num_training : ]\n",
    "\n",
    "# setup classifier and predictions\n",
    "rev_tfidf_clf = train_SVM( rev_train_tfidf_X, rev_train_tfidf_y )\n",
    "rev_pred_train_tfidf_y = rev_tfidf_clf.predict( rev_train_tfidf_X )\n",
    "rev_pred_test_tfidf_y = rev_tfidf_clf.predict( rev_test_tfidf_X )\n",
    "\n",
    "# display classifier reports - TfIdf\n",
    "print(\"Term Frequency - Inverse Document Frequency (Tf-Idf) prediction:\\n1) Train, 2) Test\\n\")\n",
    "print(classification_report(rev_train_tfidf_y, rev_pred_train_tfidf_y))\n",
    "print(classification_report(rev_test_tfidf_y, rev_pred_test_tfidf_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf-idf classifier had a lower training accuracy at 77%, but while the variance in training-to-test accuracy was lesser, so was the accuracy itself, coming down to 58% for test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yelp reviews on its site include a consumer's name, Yelp standing, as well as their photo and potential other personal information. These categories of data were left out of the dataset used in this investigation because they are not relevant to potential analysis and therefore should be left anonymous. It's still possible that the text of a review contains personal information, but because we observe the data at this degree of anonymity and because the text data is processed by vectorizers and not human analysis, this is can be considered negligible.\n",
    "\n",
    "It terms of the ethics of conducting this investigation, it could be useful to the business owners and community organizers receiving (and occasionally battling) these Yelp ratings to know how reasonable the correlation between review content and review rating is in practice. On the other hand, demonstrating a lack of correlation between these could ultimately undermine the consumer's review and/or the Yelp rating system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not appear that review content is a true predictor of a Yelp review's rating on its 5-star scale, or that any particular rating sees more accurate predictions than another. The 5-star rating in particular did see mid-high range performance in both train/test sets for both BoW and Tf-Idf, but it still did not meet the threshold for signficance. The hypothesis suggested lower ratings would be more accurate and this was not able to be addressed by the dataset or the analysis applied.\n",
    "\n",
    "This dataset was restricted by its original parameters in that it only included the Yelp reviews of parks in San Diego, which is not necessarily a large population or a common practice when visiting a park. The ratings were scattered and few for each park, although the dominant rating observed was the 5-star. Had there been anything statistically significant observed in this investigation, it would still need to be shown that this dataset could have practical significance outside of the realm of parks in San Diego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
