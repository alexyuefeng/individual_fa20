{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I intended to find the predictability of park review scores based on the text of the review. I looked at the dataset of reviews on places in San Diego and narrowed it down to just parks in San Diego. From this analysis, I found that positive reviews are easier to predict than negative reviews. The data seems to suggest that there is more variety in the words used in negative reviews versus positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name & GitHub ID\n",
    "\n",
    "- Name: Connor Isenman\n",
    "- GitHub Username: Konnur-I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are positive reviews of parks in San Diego more predictable than negative reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 57 recreation centers, 13 aquatic centers, and approximately 260 playgrounds in 8,700 acres of developed parks the San Diego Parks and Recreation department is spread thin when it comes to deciding where to put money for future expansions and upgrades [1]. In Balboa Park alone over 300 million dollars is required for much needed repairs and upkeep in the park but the money is instead being put towards parking projects in the park [2]. This kind of misallocation of funds could be avoided by looking at the relationship between traffic and budgets for improvements.\n",
    "\n",
    "In order to more efficiently allocate funds for parks around the city I believe it would be beneifical to know what traffic is like in areas when determining their budgets for improvement so we can allocate more money for road improvements or facility improvements accordingly. San Diego Parks and Recreations had a total budget of just over 116 million dollars in 2019, being able to efficiently allocate the budgeted money could help save the city thousands of dollars that would be spent on underutilized facilities or roads because they didn't analyze what areas would benefit from different improvements [3].\n",
    "\n",
    "References (include links):\n",
    "\n",
    "- 1)https://www.sandiego.gov/sites/default/files/v3parkandrec_0.pdf\n",
    "- 2)https://www.sandiegouniontribune.com/opinion/commentary/sdut-utbg-balboa-park-plaza-oppose-2016jul22-htmlstory.html\n",
    "- 3)https://www.sandiego.gov/sites/default/files/fiscal_year_2020_parks_and_recreation_department_adopted_budget.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive reviews are more predictable than negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Dataset Name: yelp_SD_reviews.csv\n",
    "- Link to the dataset: https://raw.githubusercontent.com/COGS108/individual_fa20/master/data/yelp_SD_reviews.csv\n",
    "- Number of observations: 2333\n",
    "\n",
    "This dataset is a collection of Yelp reviews on places in San Diego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Connor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Connor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://raw.githubusercontent.com/COGS108/individual_fa20/master/data/yelp_SD_reviews.csv'\n",
    "download1 = requests.get(url1).content\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(io.StringIO(download1.decode('utf-8')))\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = 'word', max_features = 2000, tokenizer = word_tokenize, \n",
    "                                     stop_words = stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['id'].str.contains(' Park')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rating(rating):\n",
    "    if rating >= 3:\n",
    "        output = 1.0\n",
    "    elif rating < 3:\n",
    "        output = 0.0\n",
    "    else:\n",
    "        output = rating\n",
    "        \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have removed all ids not containing the word park in order to narrow the data to just parks in San Diego instead of any Yelp review in San Diego. I have also converted the ratings into a binary positive or negative (1.0 or 0.0) based on the rating being 3 or above for positive and below 3 for negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['id'].str.contains(' Park')]\n",
    "df1['y'] = df1['rating'].apply(convert_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first cell I created two arrays, PR_X using the vectorizer to vectorize the text in each review and PR_y using the positive or negative column from the orinigal dataframe.\n",
    "\n",
    "Then I set two ints based off 20% of the rows and 80% of the rows, the 80% to train the SVM and 20% to test the prediction are accuarate. Next I split the arrays into training  and testing groups using the variables defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR_X = vectorizer.fit_transform(df1['text']).toarray()\n",
    "PR_y = np.array(df1['y'])\n",
    "\n",
    "num_testing = int(df1.shape[0] * .2)\n",
    "num_training = int(df1.shape[0] * .8)\n",
    "\n",
    "PR_train_X = PR_X[:num_training]\n",
    "PR_train_y = PR_y[:num_training]\n",
    "PR_test_X = PR_X[num_training:]\n",
    "PR_test_y = PR_y[num_training:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined a function that initializes an SVM classifier and then trains it. Then I used the training group to train the SVM which I followed up by predicting the training data to check the SVM is working correctly, next I used the test data to see if the SVM works outside of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        50\n",
      "         1.0       1.00      1.00      1.00       562\n",
      "\n",
      "    accuracy                           1.00       612\n",
      "   macro avg       1.00      1.00      1.00       612\n",
      "weighted avg       1.00      1.00      1.00       612\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.21      0.30        19\n",
      "         1.0       0.90      0.97      0.93       135\n",
      "\n",
      "    accuracy                           0.88       154\n",
      "   macro avg       0.70      0.59      0.61       154\n",
      "weighted avg       0.85      0.88      0.85       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train_SVM(X, y, kernel='linear'):\n",
    "    clf = SVC(kernel = kernel)\n",
    "    return clf.fit(X,y)\n",
    "\n",
    "PR_clf = train_SVM(PR_train_X, PR_train_y)\n",
    "\n",
    "PR_predicted_train_y = PR_clf.predict(PR_train_X)\n",
    "PR_predicted_test_y = PR_clf.predict(PR_test_X)\n",
    "\n",
    "print(classification_report(PR_train_y,PR_predicted_train_y))\n",
    "\n",
    "print(classification_report(PR_test_y, PR_predicted_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all the data collected is from a public source and the names of the reviewers have been removed there are not any obvious issues with ethics or privacy. The reviewer allowed their reviews to be seen by others and our data has no personal information therefore we are ethical and respecting their privacy with the use of this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my prediction model positive reviews are more predictable than negative reviews. This may be because the criteria for positive reviews includes more possible values (3-5) than the negative values (1-2). People making positive reviews are more likely to use the same generic words like great and amazing while negative reviews tend to explain why their experience was negative or what could have been better so there is a lot more subjectivity in negative reviews versus positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
